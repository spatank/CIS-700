{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "log_odds_corpus_level.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNiolntW+SAveStcbdEkTxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spatank/CIS-700/blob/master/Project/log_odds_corpus_level.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MVYuElf4GID",
        "colab_type": "code",
        "outputId": "d34b707c-53f1-46c2-a992-1d63f43aedbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/Drive', force_remount = True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9WdP-Wl4EjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/Drive/My Drive/CIS-700/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNNVobBb3MtG",
        "colab_type": "code",
        "outputId": "43fa4793-fa46-4b48-9afd-4188aec14774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data\t\t\t\t  log_odds_corpus_level.ipynb\n",
            "draco_verb_network_ff.graphml\t  log_odds.ipynb\n",
            "global_A_large.mat\t\t  networks.ipynb\n",
            "global_verb_network_ff.graphml\t  __pycache__\n",
            "harry_verb_network_ff.graphml\t  ron_verb_network_ff.graphml\n",
            "hermione_verb_network_ff.graphml  util.py\n",
            "hp_narrative_chains.py\t\t  voldemort_verb_network_ff.graphml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfucFDZkiECb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "631b71ea-f0f3-44fa-9718-bd0d9ddeb173"
      },
      "source": [
        "!ls Data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04212020\n",
            "04292020\n",
            "Canon\n",
            "hpcanon_sr_narrative_chains_counts_NNPs.txt\n",
            "hpc_raw_text.txt\n",
            "hpff_raw_text_reduced.txt\n",
            "hpff_raw_text.txt\n",
            "hpff_sr_narrative_chains_counts_NNPs_new.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mETATkADiG15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ca58d54e-3e75-433a-be19-a2c144e81a04"
      },
      "source": [
        "import collections\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGQcjoEtiImn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "canon_word_counts = collections.Counter()\n",
        "\n",
        "with open('Data/hpc_raw_text.txt', encoding = 'utf-8', errors = 'ignore') as f:\n",
        "  for line in f:\n",
        "    words = nltk.word_tokenize(line.strip())\n",
        "    words_no_punctuation = [word.lower() for word in words if word.isalnum()]\n",
        "    canon_word_counts.update(words_no_punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cos5X3Jqc49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import islice\n",
        "\n",
        "corpus_path = 'Data/hpff_raw_text.txt'\n",
        "file = open(corpus_path, encoding = 'UTF-8', errors = 'ignore').readlines()\n",
        "file_len = len(file)\n",
        "num_lines_keep = round(0.10 * file_len)\n",
        "num_lines_discard = file_len - num_lines_keep\n",
        "lines_in_sets = [num_lines_keep, num_lines_discard]\n",
        "temp = iter(file) \n",
        "splits = [list(islice(temp, 0, ele)) for ele in lines_in_sets] \n",
        "# split 0 is data to keep\n",
        "with open('Data/hpff_raw_text_reduced.txt', 'w') as f:\n",
        "  for line in splits[0]:\n",
        "    f.write('%s\\n' % line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTWPprKZiVSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fan_fiction_word_counts = collections.Counter()\n",
        "\n",
        "with open('Data/hpff_raw_text_reduced.txt', encoding = 'utf-8', errors = 'ignore') as f:\n",
        "  for line in f:\n",
        "    words = nltk.word_tokenize(line.strip())\n",
        "    words_no_punctuation = [word.lower() for word in words if word.isalnum()]\n",
        "    fan_fiction_word_counts.update(words_no_punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6JcWPi_tMTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d41e16bb-391f-4547-d1a0-b5c8865499eb"
      },
      "source": [
        "keys_a = set(canon_word_counts.keys())\n",
        "keys_b = set(fan_fiction_word_counts.keys())\n",
        "intersection = keys_a & keys_b # '&' operator is used for set intersection\n",
        "print(len(intersection))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ERBew5pk_ml",
        "colab_type": "text"
      },
      "source": [
        "What words appear more often in fan fiction than the canonical Harry Potter books?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgGMX9IAk3ZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "26b0b31f-a785-45d7-bb37-41ed2fb1c7b9"
      },
      "source": [
        "total_num_words_in_fan_fiction = sum(fan_fiction_word_counts.values())\n",
        "total_num_words_in_canon = sum(canon_word_counts.values())\n",
        "\n",
        "log_odds_data = {}\n",
        "\n",
        "for word in canon_word_counts.keys():\n",
        "  \n",
        "  count_canon = canon_word_counts[word]\n",
        "  count_fan_fiction = fan_fiction_word_counts[word]\n",
        "  \n",
        "  log_prob_canon = np.log(count_canon) - np.log(total_num_words_in_canon)\n",
        "  log_prob_fan_fiction = np.log(count_fan_fiction) - np.log(total_num_words_in_fan_fiction)\n",
        "  \n",
        "\n",
        "  if log_prob_fan_fiction != 0:\n",
        "    log_odds = log_prob_fan_fiction - log_prob_canon\n",
        "    log_odds_data[word] = log_odds"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2wBq1XSsaKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "b5fdd44f-d48a-4b44-eacc-35f4caf55870"
      },
      "source": [
        "log_odds_tuples = [(word, log_odds) for word, log_odds in log_odds_data.items()]\n",
        "log_odds_tuples = sorted(log_odds_tuples, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for i in range(0, 50):\n",
        "  print(log_odds_tuples[i])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('scorpius', 5.50767680151591)\n",
            "('guy', 4.87872015645234)\n",
            "('alright', 4.801797083271262)\n",
            "('haired', 4.610930665714724)\n",
            "('figured', 4.507773400741616)\n",
            "('dorm', 4.474203815018763)\n",
            "('emma', 4.362182951238399)\n",
            "('hugo', 4.3188274752575)\n",
            "('amy', 4.314108521323547)\n",
            "('anyways', 4.241412163135381)\n",
            "('shit', 4.2333003566000045)\n",
            "('colour', 3.883710788518899)\n",
            "('characters', 3.8811400930157998)\n",
            "('uh', 3.8484360665979906)\n",
            "('victoire', 3.7774941084252127)\n",
            "('iris', 3.7767800776915568)\n",
            "('trio', 3.7164232771506587)\n",
            "('evan', 3.67141956203373)\n",
            "('defence', 3.617616856040753)\n",
            "('commented', 3.604125926299739)\n",
            "('marlene', 3.5870022202211462)\n",
            "('alice', 3.5820967133417216)\n",
            "('crap', 3.5748387340279493)\n",
            "('honey', 3.566059046375903)\n",
            "('dorcas', 3.5607539941462107)\n",
            "('wards', 3.5572015925418423)\n",
            "('arse', 3.5301485450701318)\n",
            "('ok', 3.430257505216842)\n",
            "('kisses', 3.4262089166908414)\n",
            "('blaise', 3.414648094289765)\n",
            "('review', 3.40031883285398)\n",
            "('besides', 3.3763025110944316)\n",
            "('catherine', 3.359820590157657)\n",
            "('dating', 3.348192552162537)\n",
            "('awhile', 3.284822938229949)\n",
            "('voldermort', 3.2539782628788494)\n",
            "('theodore', 3.2515657164734666)\n",
            "('hazel', 3.227114620609301)\n",
            "('andrew', 3.2045855075492735)\n",
            "('kinda', 3.1944073026335165)\n",
            "('bastard', 3.1892790862665965)\n",
            "('freddie', 3.1763422952358784)\n",
            "('replies', 3.1605939382677395)\n",
            "('messy', 3.1486177472210244)\n",
            "('shirt', 3.145936780467766)\n",
            "('accent', 3.1445935969212986)\n",
            "('ellie', 3.1392027482864204)\n",
            "('chapters', 3.1269660218379833)\n",
            "('john', 3.11596178424697)\n",
            "('whilst', 3.1118037740983073)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZY2rnv8wMnI",
        "colab_type": "text"
      },
      "source": [
        "# Canon with Standard English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_dx6OTMwQ3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "87428be8-2be7-43e0-eb7d-a2b36866e8d1"
      },
      "source": [
        "!pip install wordfreq\n",
        "import wordfreq"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wordfreq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/7f/029a2d22362e785a258cd8bd5725f453817decfb31ac5d6dff0c472303d3/wordfreq-2.2.2.tar.gz (32.8MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8MB 119kB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from wordfreq) (1.0.0)\n",
            "Collecting langcodes>=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/1d/9b5ad179234206ad52f863c314851db7a00f69770c51d40c12c7513e628f/langcodes-2.0.0.tar.gz (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 42.1MB/s \n",
            "\u001b[?25hCollecting regex<=2018.02.21,>=2017.07.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/51/c39562cfed3272592c60cfd229e5464d715b78537e332eac2b695422dc49/regex-2018.02.21.tar.gz (620kB)\n",
            "\u001b[K     |████████████████████████████████| 624kB 42.2MB/s \n",
            "\u001b[?25hCollecting marisa-trie\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 43.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordfreq, langcodes, regex, marisa-trie\n",
            "  Building wheel for wordfreq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordfreq: filename=wordfreq-2.2.2-cp36-none-any.whl size=32816665 sha256=bac08424126b2e040b916de005df39a74e4c3f286178f3cd118a676aec87ff40\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/2e/fc/e447859743f61cdf41873a5bcc11300c05fbd27631aea984e1\n",
            "  Building wheel for langcodes (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langcodes: filename=langcodes-2.0.0-cp36-none-any.whl size=5044047 sha256=3ed0402d66f3e76d05e2b17bef27e6d0cf6a0e4d1b38edb5a27d28fde3947bb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/11/90/c7bba8118f3674d75e1457537635266a12538cf622a4684bb2\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2018.2.21-cp36-cp36m-linux_x86_64.whl size=552310 sha256=3ee6fd822e79d107a2fef349efaa9cef8b71477990811199de2c320c904b919a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/c9/cf/230425cdd343d6b98e8da5a5841c3dab1e0c8aaa134e29edb0\n",
            "  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=861407 sha256=110aad61e0380bc4e568d7829a27fc8ee138f8c5170ef411215bf14a0145a861\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
            "Successfully built wordfreq langcodes regex marisa-trie\n",
            "Installing collected packages: marisa-trie, langcodes, regex, wordfreq\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "Successfully installed langcodes-2.0.0 marisa-trie-0.7.5 regex-2018.2.21 wordfreq-2.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "regex"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qtqCwzQxR7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_num_words_in_canon = sum(canon_word_counts.values())\n",
        "\n",
        "log_odds_data = {}\n",
        "\n",
        "for word in canon_word_counts.keys():\n",
        "  count_canon = canon_word_counts[word]\n",
        "\n",
        "  log_prob_canon = np.log(count_canon) - np.log(total_num_words_in_canon)\n",
        "  log_prob_english = wordfreq.zipf_frequency(word, lang=\"en\")\n",
        "\n",
        "  if log_prob_english != 0:\n",
        "    log_odds = log_prob_canon - log_prob_english\n",
        "    log_odds_data[word] = log_odds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePo1O2MLxrMd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "f6ed50f3-46a6-4779-ef3e-10bcb8b2f03d"
      },
      "source": [
        "log_odds_tuples = [(word, log_odds) for word, log_odds in log_odds_data.items()]\n",
        "log_odds_tuples = sorted(log_odds_tuples, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for i in range(0, 50):\n",
        "  print(log_odds_tuples[i])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('hermione', -8.553356963296721)\n",
            "('hagrid', -8.755619612117385)\n",
            "('harry', -8.833787911198272)\n",
            "('dumbledore', -8.84744015807585)\n",
            "('weasley', -9.130941622583435)\n",
            "('malfoy', -9.207863910463326)\n",
            "('snape', -9.251193306242097)\n",
            "('harrys', -9.291742064769004)\n",
            "('ron', -9.394647261463543)\n",
            "('slughorn', -9.534338152023214)\n",
            "('mcgonagall', -9.549610976581542)\n",
            "('kreacher', -9.622336642291202)\n",
            "('voldemort', -9.812289512555745)\n",
            "('umbridge', -9.87077303339843)\n",
            "('dursleys', -9.888013929752669)\n",
            "('wand', -9.898043790903325)\n",
            "('lupin', -9.991193221767068)\n",
            "('griphook', -9.995416533186516)\n",
            "('goyle', -10.004590909420527)\n",
            "('pomfrey', -10.010253390232512)\n",
            "('gryffindor', -10.07226512797336)\n",
            "('filch', -10.11488924532895)\n",
            "('wormtail', -10.117734460734736)\n",
            "('scabbers', -10.130342183403194)\n",
            "('ginny', -10.14061810509459)\n",
            "('rons', -10.148417883578317)\n",
            "('crookshanks', -10.150835304375411)\n",
            "('sirius', -10.17844784735874)\n",
            "('hogwarts', -10.185652334844406)\n",
            "('said', -10.274874839756961)\n",
            "('scrimgeour', -10.314864254023686)\n",
            "('dobby', -10.344799186141913)\n",
            "('dementors', -10.356673805437609)\n",
            "('snapes', -10.44596232339531)\n",
            "('slytherins', -10.44667026689169)\n",
            "('bagman', -10.458273601103153)\n",
            "('ollivander', -10.469343429395803)\n",
            "('trelawney', -10.481105797480787)\n",
            "('firebolt', -10.493303492912606)\n",
            "('weasleys', -10.494745837724366)\n",
            "('quidditch', -10.495685997588934)\n",
            "('krum', -10.52130297499697)\n",
            "('buckbeak', -10.541567818513418)\n",
            "('flitwick', -10.576504225166355)\n",
            "('he', -10.599455990466893)\n",
            "('dyou', -10.60596232339531)\n",
            "('greyback', -10.606814420024406)\n",
            "('borgin', -10.630231870476555)\n",
            "('petunia', -10.633920213958376)\n",
            "('slytherin', -10.641366531678086)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nkm3ftiwIS-",
        "colab_type": "text"
      },
      "source": [
        "# Fan Fiction with Standard English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84DdYwW0yOly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_num_words_in_fan_fiction = sum(fan_fiction_word_counts.values())\n",
        "\n",
        "log_odds_data = {}\n",
        "\n",
        "for word in fan_fiction_word_counts.keys():\n",
        "  count_fan_fiction = fan_fiction_word_counts[word]\n",
        "\n",
        "  log_prob_fan_fiction = np.log(count_fan_fiction) - np.log(total_num_words_in_fan_fiction)\n",
        "  log_prob_english = wordfreq.zipf_frequency(word, lang=\"en\")\n",
        "\n",
        "  if log_prob_english != 0:\n",
        "    log_odds = log_prob_fan_fiction - log_prob_english\n",
        "    log_odds_data[word] = log_odds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDNlWOmQyQaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "8f59db51-e70b-4da1-fbb6-4c0dccff81b5"
      },
      "source": [
        "log_odds_tuples = [(word, log_odds) for word, log_odds in log_odds_data.items()]\n",
        "log_odds_tuples = sorted(log_odds_tuples, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for i in range(0, 50):\n",
        "  print(log_odds_tuples[i])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('hermione', -8.933544474984508)\n",
            "('remus', -9.450006376913379)\n",
            "('ginny', -9.46480384054967)\n",
            "('draco', -9.472216011416899)\n",
            "('sirius', -9.500748395124791)\n",
            "('malfoy', -9.660939644119985)\n",
            "('harry', -9.84429530706121)\n",
            "('weasley', -10.016087966340125)\n",
            "('dumbledore', -10.059386108895115)\n",
            "('snape', -10.226584996194157)\n",
            "('pomfrey', -10.268017451460269)\n",
            "('mcgonagall', -10.274376769421487)\n",
            "('ron', -10.302354345524574)\n",
            "('lily', -10.32246087496647)\n",
            "('albus', -10.32789649242774)\n",
            "('hogwarts', -10.346175047028712)\n",
            "('gryffindor', -10.388617638049407)\n",
            "('voldemort', -10.423256454010946)\n",
            "('slytherins', -10.549085599609398)\n",
            "('scorpius', -10.553014510109037)\n",
            "('she', -10.55924394137414)\n",
            "('her', -10.567611971978383)\n",
            "('severus', -10.611834698062976)\n",
            "('slytherin', -10.620285057261597)\n",
            "('wand', -10.648206295309455)\n",
            "('muggle', -10.6812717337462)\n",
            "('nodded', -10.698496239523761)\n",
            "('quidditch', -10.777603670275038)\n",
            "('he', -10.78328324705663)\n",
            "('padfoot', -10.799279148489566)\n",
            "('i', -10.805122244364352)\n",
            "('auror', -10.81074291948009)\n",
            "('sighed', -10.84352209824361)\n",
            "('ravenclaw', -10.91776878346863)\n",
            "('tonks', -10.971328216582851)\n",
            "('the', -10.972222273459714)\n",
            "('smiled', -10.974447014404792)\n",
            "('to', -10.975964443740203)\n",
            "('was', -10.980974412867953)\n",
            "('narcissa', -10.987128963512912)\n",
            "('aurors', -11.006986294400432)\n",
            "('gryffindors', -11.018648833142745)\n",
            "('and', -11.033328615493922)\n",
            "('hagrid', -11.046347856761177)\n",
            "('his', -11.053664021598937)\n",
            "('hogsmeade', -11.059816459363502)\n",
            "('muttered', -11.083083325412618)\n",
            "('potter', -11.103575577640395)\n",
            "('lupin', -11.123102010746436)\n",
            "('you', -11.158180277079943)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}