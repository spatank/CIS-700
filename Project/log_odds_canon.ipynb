{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "log_odds_canon.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNFUZgg1Azn6w4ur+TLbEo4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spatank/CIS-700/blob/master/Project/log_odds_canon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btKFC_sV39ef",
        "colab_type": "text"
      },
      "source": [
        "# Google Drive Initialization and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MVYuElf4GID",
        "colab_type": "code",
        "outputId": "8e329643-acd7-4132-d558-925eab19a41a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/Drive', force_remount = True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9WdP-Wl4EjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('Drive/My Drive/CIS-700')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNNVobBb3MtG",
        "colab_type": "code",
        "outputId": "3fe5f703-a139-438d-db8f-8ad9c9355508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!ls Data/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04212020\n",
            "04292020\n",
            "Canon\n",
            "hpcanon_sr_narrative_chains_counts_NNPs.txt\n",
            "hpc_raw_text.txt\n",
            "hpff_raw_text_reduced.txt\n",
            "hpff_raw_text.txt\n",
            "hpff_sr_narrative_chains_counts_NNPs_new.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w11fjs43NtU",
        "colab_type": "code",
        "outputId": "07f753b1-808b-4b38-c562-8971efcdde76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import util\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "from nltk.util import ngrams\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "from textblob import TextBlob # for sentiment analysis\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "import scipy.io as sio"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiNZjeJT2_x1",
        "colab_type": "text"
      },
      "source": [
        "# Extract Event Chains by Character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J6tVLjwxaTO",
        "colab_type": "code",
        "outputId": "d5fba01a-a18b-4fea-d739-ee9c381203cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_path = 'Data/hpcanon_sr_narrative_chains_counts_NNPs.txt'\n",
        "data = util.load_json(data_path)\n",
        "all_verbs = []\n",
        "verbs_dict = {}\n",
        "for cluster, narrative_chains in data.items(): \n",
        "  tag = nltk.tag.pos_tag([cluster])[0][1] # get cluster tag\n",
        "  # filter for noun phrases\n",
        "  if tag in ['NN', 'NNP', 'NNS']: \n",
        "    verb_chains = []\n",
        "    # convert list of actions by the character into a Pandas DataFrame\n",
        "    df = pd.DataFrame.from_records(narrative_chains)  \n",
        "    # split the ['story','chapter'] column into 'story' and 'chapter' columns\n",
        "    df[['story','chapter']] = pd.DataFrame(df[0].values.tolist(), index = df.index)\n",
        "    # remove the now redundant ['story','chapter'] column\n",
        "    df.drop(df.columns[0], axis = 1, inplace = True)\n",
        "    # move 'story' and 'chapter' columns to the front for ease of viewing\n",
        "    cols = list(df)\n",
        "    # grab the 'chapter' column and place at the front of the DataFrame\n",
        "    cols.insert(0, cols.pop(cols.index('chapter')))\n",
        "    df = df.loc[:, cols]\n",
        "    # now grab the 'story' column and place at the front of the DataFrame\n",
        "    cols.insert(0, cols.pop(cols.index('story')))\n",
        "    df = df.loc[:, cols]\n",
        "    # group the DataFrame for this character by the story number\n",
        "    story_groups = df.groupby(by = 'story')\n",
        "    # now iterate over the grouped stories to group by chapter number\n",
        "    for story_idx in story_groups.groups:\n",
        "      # get the story group as a DataFrame to allow grouping by chapter\n",
        "      story = story_groups.get_group(story_idx)\n",
        "      # print(story)\n",
        "      chapter_groups = story.groupby(by = 'chapter')\n",
        "      for chapter_idx in chapter_groups.groups:\n",
        "        # get the chapter group as a DataFrame \n",
        "        chapter = chapter_groups.get_group(chapter_idx)\n",
        "        # print(chapter)\n",
        "        chapter_action_chain = []\n",
        "        for idx, row in chapter.iterrows():\n",
        "          # column titled '2' corresponds to the verb, check that it exists\n",
        "          # if it is present in the DataFrame, check that it is not None\n",
        "          # 0-th entry corresponds to the semantic role\n",
        "          if 2 in row.index:\n",
        "            if row[2] is not None:\n",
        "              if row[2][0] == 'B-V': \n",
        "                verb = lemmatizer.lemmatize(row[2][1], 'v') \n",
        "                chapter_action_chain.append(verb)\n",
        "                all_verbs.append(verb)\n",
        "        # a single action is uninteresting from a narrative chain perspective\n",
        "        if len(chapter_action_chain) > 1:\n",
        "          verb_chains.append(chapter_action_chain)\n",
        "    verbs_dict[cluster] = verb_chains"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Path:  Data/hpcanon_sr_narrative_chains_counts_NNPs.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHhpGhBpO0VV",
        "colab_type": "code",
        "outputId": "f0f53fe2-f61e-41cc-ab1a-01ada830d6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "c = Counter(all_verbs)\n",
        "print(c)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'be': 29, 'think': 11, 'say': 9, 'leave': 8, 'go': 8, 'stand': 7, 'give': 7, 'look': 6, 'get': 6, 'fell': 5, 'star': 5, 'like': 5, 'know': 4, 'rise': 4, 'felt': 4, 'make': 4, 'watch': 3, 'stride': 3, 'lay': 3, 'put': 3, 'saw': 3, 'pull': 3, 'raise': 3, 'have': 3, 'come': 3, 'see': 3, 'take': 3, 'become': 3, 'hang': 3, 'want': 2, 'press': 2, 'realize': 2, 'hide': 2, 'expect': 2, 'set': 2, 'walk': 2, 'follow': 2, 'meet': 2, 'recognize': 2, 'feel': 2, 'draw': 2, 'join': 2, 'whip': 2, 'climb': 2, 'hit': 2, 'wave': 2, 'hold': 2, 'hat': 2, 'knock': 2, 'throw': 2, 'close': 2, 'do': 2, 'twist': 2, 'care': 2, 'rumble': 2, 'force': 2, 'blink': 1, 'roll': 1, 'wake': 1, 'remember': 1, 'find': 1, 'heave': 1, 'faint': 1, 'slump': 1, 'grin': 1, 'wrench': 1, 'storm': 1, 'fume': 1, 'hear': 1, 'check': 1, 'choose': 1, 'buy': 1, 'clamber': 1, 'hurry': 1, 'tell': 1, 'unclench': 1, 'spin': 1, 'sleep': 1, 'doze': 1, 'endure': 1, 'traipse': 1, 'appreciate': 1, 'understand': 1, 'remain': 1, 'squeeze': 1, 'could': 1, 'suffocate': 1, 'breathe': 1, 'crumple': 1, 'burn': 1, 'live': 1, 'listen': 1, 'cling': 1, 'avoid': 1, 'grope': 1, 'smash': 1, 'fight': 1, 'keep': 1, 'let': 1, 'people meeting in secret all over the country': 1, 'disagree': 1, 'agree': 1, 'send': 1, \"'m\": 1, 'rid': 1, 'execute': 1, 'Snape': 1, 'reach': 1, 'believe': 1, 'clear': 1, 'read': 1, 'hop': 1, 'seize': 1, 'learn': 1, 'glaze': 1, 'hand': 1, 'sit': 1, 'desire': 1, 'drag': 1, 'turn': 1, 'lose': 1, 'tremble': 1, 'leap': 1, 'lead': 1, 'start': 1, 'dress': 1, 'scramble': 1, 'outstretched': 1, 'unstick': 1, 'stop': 1, 'speak': 1, 'scowl': 1, 'Kreacher': 1, 'smile': 1, 'kneel': 1, 'click': 1, 'splash': 1, 'dance': 1, 'wear': 1, 'shake': 1, 'step': 1, \"'s\": 1, 'wail': 1, 'sob': 1, 'fly': 1, 'blast': 1, 'droop': 1, 'break': 1, 'HEARD': 1, 'sweep': 1, 'a third unique flame , which shot from the wand': 1, 'bind': 1, 'dismiss': 1, 'slam': 1, 'move': 1, 'indicate': 1, 'discuss': 1, 'suspend': 1, 'begin': 1, 'howl': 1, 'sway': 1, 'slither': 1, 'teeter': 1, 'hustle': 1, 'dwell': 1, 'drift': 1, 'point': 1, 'shriek': 1, 'run': 1, 'stretch': 1, 'stagger': 1, 'launch': 1, 'buckle': 1, 'possess': 1, 'precede': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV9JZIeSOMuP",
        "colab_type": "code",
        "outputId": "f2dc5a19-102f-4188-a4df-1d898aad35e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(all_verbs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2UMlQ2UOHa-",
        "colab_type": "code",
        "outputId": "d4f58e6c-e2b0-4e8a-afbc-806a6c263dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(np.unique(all_verbs))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9qlhn4Vn8u2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # most common verbs\n",
        "# filtered_ten = [word for word, cnt in c.most_common(10)]\n",
        "# filtered_ten\n",
        "\n",
        "# least common verbs\n",
        "# filtered_ten = c.most_common()[:-10:-1]\n",
        "# filtered_ten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjQmisJyoMU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_list_verbs = [verb for verb in all_verbs if verb in filtered_ten]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMgRqjBpNcol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fig, ax = plt.subplots()\n",
        "# n, bins, patches = ax.hist(new_list_verbs, bins = 'auto') \n",
        "# ax.tick_params(labelcolor = 'w', labelsize = 'large', width = 3)\n",
        "# fig.tight_layout()\n",
        "# # ax.set_title(\"Histogram of Verb Frequency\")\n",
        "# plt.savefig('most_common_hist.png')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPfvRSkIHRqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# g_global = nx.DiGraph()\n",
        "# g_global.add_nodes_from(np.unique(all_verbs))\n",
        "\n",
        "# for character, verb_chains in verbs_dict.items():\n",
        "#   for verb_chain in verb_chains:\n",
        "#     edges_between = list(ngrams(verb_chain, 2))\n",
        "#     for edge in edges_between:\n",
        "#       from_node = edge[0]\n",
        "#       to_node = edge[1]\n",
        "#       if from_node == to_node:\n",
        "#         continue # skip a self-edge\n",
        "#       if g_global.has_edge(from_node, to_node):\n",
        "#         g_global[from_node][to_node]['weight'] += 1\n",
        "#       else:\n",
        "#         g_global.add_edge(from_node, to_node, weight = 1)\n",
        "\n",
        "# nx.write_graphml(g_global, 'global_verb_network_ff.graphml')\n",
        "# A = nx.adjacency_matrix(g_global, nodelist = np.unique(all_verbs), weight = 'weight')\n",
        "# sio.savemat('global_A_large.mat', dict(A = A.todense()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suByLrMGWUGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all_graphs = {}\n",
        "\n",
        "# for character, verb_chains in verbs_dict.items():\n",
        "#   # get the verbs for this character\n",
        "#   char_verbs = np.unique([verb for verb_chain in verb_chains for verb in verb_chain])\n",
        "#   g = nx.DiGraph()\n",
        "#   g.add_nodes_from(char_verbs)\n",
        "#   # each value in the verbs_dict is a list of lists\n",
        "#   # each sub-list is a chain of verbs \n",
        "#   for verb_chain in verb_chains:\n",
        "#     edges_between = list(ngrams(verb_chain, 2))\n",
        "#     for edge in edges_between:\n",
        "#       from_node = edge[0]\n",
        "#       to_node = edge[1]\n",
        "#       if from_node == to_node:\n",
        "#         continue # skip a self-edge\n",
        "#       if g.has_edge(from_node, to_node):\n",
        "#         g[from_node][to_node]['weight'] += 1\n",
        "#       else:\n",
        "#         g.add_edge(from_node, to_node, weight = 1)\n",
        "#   all_graphs[character] = g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpXfRJsGSsja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# draco_graph = all_graphs['Draco']\n",
        "# nx.write_graphml(draco_graph, 'draco_verb_network_ff.graphml')\n",
        "# nx.draw(draco_graph, with_labels = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk5f62h8XCbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# harry_graph = all_graphs['Harry']\n",
        "# nx.write_graphml(harry_graph, 'harry_verb_network_ff.graphml')\n",
        "# nx.draw(harry_graph, with_labels = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYDV2NJdXDPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hermione_graph = all_graphs['Hermione']\n",
        "# nx.write_graphml(hermione_graph, 'hermione_verb_network_ff.graphml')\n",
        "# nx.draw(hermione_graph, with_labels = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5gIq4nQTvyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ron_graph = all_graphs['Ron']\n",
        "# nx.write_graphml(ron_graph, 'ron_verb_network_ff.graphml')\n",
        "# nx.draw(ron_graph, with_labels = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylo2A7VImsi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# voldemort_graph = all_graphs['Voldemort']\n",
        "# nx.write_graphml(voldemort_graph, 'voldemort_verb_network_ff.graphml')\n",
        "# nx.draw(voldemort_graph, with_labels = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLCYiwtnE9nZ",
        "colab_type": "text"
      },
      "source": [
        "# Log-Odds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HezPlq8yPk0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sorted_log_odds(character_of_interest, n, verbs_dict):\n",
        "  all_action_pairs = []\n",
        "  for character, verb_chains in verbs_dict.items():\n",
        "    if character == character_of_interest:\n",
        "      continue\n",
        "    for verb_chain in verb_chains:\n",
        "      edges_between = list(ngrams(verb_chain, n))\n",
        "      for edge in edges_between:\n",
        "        all_action_pairs.append(edge)\n",
        "  all_action_pairs = Counter(all_action_pairs)\n",
        "  total_action_pairs = sum(all_action_pairs.values())\n",
        "\n",
        "  all_COI_action_chains = verbs_dict[character_of_interest]\n",
        "  all_COI_action_pairs = []\n",
        "  for verb_chain in all_COI_action_chains:\n",
        "    edges_between = list(ngrams(verb_chain, n))\n",
        "    for edge in edges_between:\n",
        "      all_COI_action_pairs.append(edge)\n",
        "  all_COI_action_pairs = Counter(all_COI_action_pairs)\n",
        "  total_COI_action_pairs = sum(all_COI_action_pairs.values())\n",
        "\n",
        "  log_odds_data = {}\n",
        "\n",
        "  for pair in all_COI_action_pairs.keys():\n",
        "\n",
        "    count_pair_COI = all_COI_action_pairs[pair]\n",
        "    log_prob_COI = np.log(count_pair_COI) - np.log(total_COI_action_pairs)\n",
        "\n",
        "    count_pair_all = all_action_pairs[pair]\n",
        "    log_prob_all = np.log(count_pair_all) - np.log(total_action_pairs)\n",
        "\n",
        "    if log_prob_COI != 0:\n",
        "      log_odds = log_prob_all - log_prob_COI\n",
        "      log_odds_data[pair] = log_odds\n",
        "\n",
        "  log_odds_tuples = [(pair, log_odds) for pair, log_odds in log_odds_data.items()]\n",
        "  log_odds_tuples = sorted(log_odds_tuples, key = lambda x: x[1], reverse = True)\n",
        "\n",
        "  return log_odds_tuples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiOytFYGFBHr",
        "colab_type": "code",
        "outputId": "b4354565-c971-4213-f888-295b19b577f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "character_of_interest = 'Voldemort'\n",
        "n = 1 # order parameter for verb chain\n",
        "\n",
        "log_odds = get_sorted_log_odds(character_of_interest, n, verbs_dict)\n",
        "\n",
        "for i in range(0, 25):\n",
        "  print(log_odds[i])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e2dc18ecb801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_odds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt9KGCZeMidE",
        "colab_type": "code",
        "outputId": "effb3080-a4ca-449d-863f-00e0575b6f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "character_of_interest = 'Hermione'\n",
        "n = 1 # order parameter for verb chain\n",
        "\n",
        "log_odds = get_sorted_log_odds(character_of_interest, n, verbs_dict)\n",
        "\n",
        "for i in range(0, 25):\n",
        "  print(log_odds[i])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(('think',), 0.08583143584978137)\n",
            "(('give',), -0.06831924397747713)\n",
            "(('like',), -0.4737843520856413)\n",
            "(('leave',), -0.4737843520856413)\n",
            "(('be',), -0.6814237168638857)\n",
            "(('go',), -1.4546136050973675)\n",
            "(('say',), -1.4546136050973675)\n",
            "(('feel',), -1.860078713205532)\n",
            "(('see',), -1.860078713205532)\n",
            "(('realize',), -1.860078713205532)\n",
            "(('saw',), -1.860078713205532)\n",
            "(('draw',), -1.860078713205532)\n",
            "(('twist',), -1.860078713205532)\n",
            "(('walk',), -1.860078713205532)\n",
            "(('take',), -1.860078713205532)\n",
            "(('believe',), -inf)\n",
            "(('do',), -inf)\n",
            "(('clear',), -inf)\n",
            "(('read',), -inf)\n",
            "(('hop',), -inf)\n",
            "(('meet',), -inf)\n",
            "(('seize',), -inf)\n",
            "(('glaze',), -inf)\n",
            "(('hand',), -inf)\n",
            "(('sit',), -inf)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ZP0q1VPFvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "41ad173c-9178-41a0-f248-45448faeb82a"
      },
      "source": [
        "character_of_interest = 'Ron'\n",
        "n = 1 # order parameter for verb chain\n",
        "\n",
        "log_odds = get_sorted_log_odds(character_of_interest, n, verbs_dict)\n",
        "\n",
        "for i in range(0, 25):\n",
        "  print(log_odds[i])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(('be',), 0.04255961441879563)\n",
            "(('think',), -0.7841189587656721)\n",
            "(('stand',), -1.3437347467010947)\n",
            "(('like',), -1.3437347467010947)\n",
            "(('make',), -1.6314168191528755)\n",
            "(('give',), -1.8137383759468304)\n",
            "(('stride',), -2.7300291078209855)\n",
            "(('throw',), -2.7300291078209855)\n",
            "(('come',), -2.7300291078209855)\n",
            "(('become',), -2.7300291078209855)\n",
            "(('unstick',), -inf)\n",
            "(('stop',), -inf)\n",
            "(('speak',), -inf)\n",
            "(('Kreacher',), -inf)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5f5dfad85005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_odds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSb8vZE1PJ-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "58f0181c-637e-4250-a8cc-989e7a771c41"
      },
      "source": [
        "character_of_interest = 'Harry'\n",
        "n = 1 # order parameter for verb chain\n",
        "\n",
        "log_odds = get_sorted_log_odds(character_of_interest, n, verbs_dict)\n",
        "\n",
        "for i in range(0, 25):\n",
        "  print(log_odds[i])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(('give',), 1.3004784415350348)\n",
            "(('get',), 0.8950133334268706)\n",
            "(('be',), 0.3841877096608797)\n",
            "(('raise',), 0.20186615286692522)\n",
            "(('fell',), -0.08581591958485557)\n",
            "(('leave',), -0.08581591958485557)\n",
            "(('star',), -0.08581591958485557)\n",
            "(('like',), -0.08581591958485557)\n",
            "(('want',), -0.4912810276930202)\n",
            "(('rise',), -0.4912810276930202)\n",
            "(('realize',), -0.4912810276930202)\n",
            "(('stride',), -0.4912810276930202)\n",
            "(('expect',), -0.4912810276930202)\n",
            "(('think',), -0.4912810276930202)\n",
            "(('walk',), -0.4912810276930202)\n",
            "(('make',), -0.4912810276930202)\n",
            "(('recognize',), -0.4912810276930202)\n",
            "(('feel',), -0.4912810276930202)\n",
            "(('draw',), -0.4912810276930202)\n",
            "(('saw',), -0.4912810276930202)\n",
            "(('wave',), -0.4912810276930202)\n",
            "(('stand',), -0.8967461358011848)\n",
            "(('watch',), -1.1844282082529656)\n",
            "(('lay',), -1.1844282082529656)\n",
            "(('put',), -1.1844282082529656)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}