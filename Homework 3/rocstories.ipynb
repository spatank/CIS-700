{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rocstories",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spatank/CIS-700/blob/master/rocstories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8bU8lIUl52o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers  # Used to compute BERT embeddings.\n",
        "\n",
        "import IPython.display\n",
        "IPython.display.clear_output()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fYZAsBxxwaH",
        "colab_type": "code",
        "outputId": "62b5482f-422a-4167-8605-3dad57361168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import csv\n",
        "import random\n",
        "import IPython.display\n",
        "\n",
        "# from tqdm.autonotebook import tqdm\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.enable_v2_behavior()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLMIU25mH574",
        "colab_type": "text"
      },
      "source": [
        "# Natural Language Understanding\n",
        "When you read a story, you understand many things about it.\n",
        "You understand who the characters are, where the story is taking place, and the events that have happened so far. Given your comprehension of the story so far and your common-sense understanding of the world, you can often predict what will or will not happen next.\n",
        "\n",
        "This skill is innate for you, but the ability to guess at likely future directions for a story is actually a really difficult task to teach computers. In this homework, you will be exploring two tasks that were designed to evaluate how well computers can tell a probable story continuation from an improbable one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAAJmHWfdOkk",
        "colab_type": "text"
      },
      "source": [
        "# ROCStories\n",
        "The [ROCStories task](https://cs.rochester.edu/nlp/rocstories/) involves predicting which sentence best ends a short story. The stories look something like this:\n",
        "\n",
        "**Story**\n",
        "```\n",
        "Dorothy's cat was pregnant.\n",
        "She didn't know how it happened.\n",
        "She convinced the family to keep the kittens.\n",
        "It wound up having 7 kittens.\n",
        "```\n",
        "**Candidate Ending 1**\n",
        "```\n",
        "Dorothy made sure to buy lots of cat food.\n",
        "```\n",
        "**Candidate Ending 2**\n",
        "```\n",
        "Dorothy went to the pet store and bought a new hamster.\n",
        "```\n",
        "\n",
        "The bad ending sentences are designed to be on topic but clearly incorrect to a human. Despite Ending 2 mentioning a pet store, you should have quickly guessed that Ending 1 is the correct one.\n",
        "\n",
        "The tricky part about ROCStories is that the training set only contains 5-sentence stories with good ending sentences.\n",
        "However, at test time you see two possible 5th sentences and need to classify which is better.\n",
        "You can read up on the dataset and how it was collected in the [paper introducing the dataset](https://www.aclweb.org/anthology/N16-1098.pdf).\n",
        "\n",
        "In this homework, you will investigate how a very simple sentiment-based approach can get reasonable accuracy at this task, revealing the challenges behind designing datasets and tasks for evaluating natural language and commonsense understanding.\n",
        "\n",
        "You will also train a neural network to perform the task, hopefully achieving higher accuracy.\n",
        "\n",
        "Lastly, if you choose to, you can submit to the official leaderboard for extra credit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCX9rCKd0ucN",
        "colab_type": "text"
      },
      "source": [
        "### Download the data\n",
        "There are two versions of the ROCStories dataset. After its original 2016 release, researchers noticed problematic biases in the data. The 2017/2018 version was an attempt to resolve these biases. You should report your results on both the 2016 and 2018 validation sets, as well as the 2016 test set. (The 2018 test set is available for download online as well, but the labels for it are still being withheld.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOpKek9JofUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Download the data\n",
        "!mkdir rocstories_data\n",
        "!wget -nc -O rocstories_data/train2017.csv https://docs.google.com/spreadsheets/d/1emH8KL8NVCCumZc2oMu-3YqRWddD3AqZEHvNqMdfgKA/export?format=csv\n",
        "!wget -nc -O rocstories_data/valid2018.csv https://docs.google.com/spreadsheets/d/1F9vtluzD3kZOn7ULKyMQZfoRnSRzRnnaePyswkRqIdY/export?format=csv\n",
        "!wget -nc -O rocstories_data/valid2016.csv https://docs.google.com/spreadsheets/d/1FkdPMd7ZEw_Z38AsFSTzgXeiJoLdLyXY_0B_0JIJIbw/export?format=csv\n",
        "!wget -nc -O rocstories_data/test2016.csv  https://docs.google.com/spreadsheets/d/11tfmMQeifqP-Elh74gi2NELp0rx9JMMjnQ_oyGKqCEg/export?format=csv\n",
        "\n",
        "IPython.display.clear_output()  # Clear the stdout/\n",
        "\n",
        "def read_rocstories_valid_csv(path):\n",
        "  examples = []\n",
        "  with open(path) as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for line in reader:\n",
        "      context = [line['InputSentence1'], line['InputSentence2'],\n",
        "                 line['InputSentence3'], line['InputSentence4']]\n",
        "      option_0 = line['RandomFifthSentenceQuiz1']\n",
        "      option_1 = line['RandomFifthSentenceQuiz2']\n",
        "      label = int(line['AnswerRightEnding']) - 1\n",
        "      examples.append({'context': context, \n",
        "                       'options': [option_0, option_1],\n",
        "                       'label': label})\n",
        "  return examples\n",
        "\n",
        "def read_rocstories_train_csv(path):\n",
        "  examples = []\n",
        "  with open(path) as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for line in reader:\n",
        "      story = [line['sentence1'], line['sentence2'],\n",
        "               line['sentence3'], line['sentence4'],\n",
        "               line['sentence5']]\n",
        "      examples.append({'story': story})\n",
        "  return examples\n",
        "\n",
        "train_data = read_rocstories_train_csv('/content/rocstories_data/train2017.csv')\n",
        "valid_2016_data = read_rocstories_valid_csv('/content/rocstories_data/valid2016.csv')\n",
        "valid_2018_data = read_rocstories_valid_csv('/content/rocstories_data/valid2018.csv')\n",
        "test_2016_data = read_rocstories_valid_csv('/content/rocstories_data/test2016.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM9JRPj-t-c1",
        "colab_type": "text"
      },
      "source": [
        "Here's what an example in the train dataset looks like:\n",
        "```\n",
        "> print(train_data[123])\n",
        "{'story': [\"Sam's dog Rex escaped from their yard.\",\n",
        "           'Sam was distraught.',\n",
        "           'He went out calling for Rex.',\n",
        "           'Then he saw Rex come running up the street!',\n",
        "           'Sam was so relieved, he almost cried!']}\n",
        "```\n",
        "Here's what an example in one of the validation datasets looks like:\n",
        "```\n",
        "> print(valid_2016_data[123])\n",
        "{'context': [\"Jen got sent to her aunt's for the summer.\",\n",
        "            'She hated the thought of being away from her local library all summer.',\n",
        "            'She took a few books with her but she would go through those quickly.',\n",
        "            'When she arrived her aunt took her into a special room in her home.'],\n",
        " 'label': 1,\n",
        " 'options': ['Jen saw her books burning in the fireplace.',\n",
        "             'The room was full of shelves of books that appealed to girls.']}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCLvj-CfG7h",
        "colab_type": "text"
      },
      "source": [
        "### Classify with sentiment analysis\n",
        "After the ROCStories dataset was released in 2016, researchers soon realized that it has undesired biases. The correct next sentences tends to be more positive than the incorrect next sentences. An updated version of the dataset was released in 2018 that attempted to eliminate this bias.\n",
        "\n",
        "Implement a function that makes a prediction based on sentiment.\n",
        "You can use either [AllenNLP](https://demo.allennlp.org/sentiment-analysis) or [TextBlob](https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis).\n",
        "Your function should compute the sentiment of each 5th sentence option and predict the one with the more positive sentiment.\n",
        "\n",
        "**In your report, list the validation and test accuracies you get with your sentiment classifier. Also show a couple of negative examples where the model incorrectly predicted the fifth sentence.**\n",
        "\n",
        "*Hint: We were able to get over 60\\% accuracy using only the sentiment of the 5th sentences, but you can also experiment with running sentiment analysis on the context sentences as well to see if you can improve upon this.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIGF4DyixSst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Computes an accuracy given the data dictionary and a list of [0, 1] predictions.\n",
        "\n",
        "def compute_accuracy(data, predictions):\n",
        "  ground_truth = np.array([ex['label'] for ex in data])\n",
        "  predictions = np.array(predictions)\n",
        "  assert len(ground_truth) == len(predictions)\n",
        "\n",
        "  return np.sum(np.equal(ground_truth, predictions)) / float(len(ground_truth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxkiF8lchbcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO2Ohaw3s3dR",
        "colab_type": "code",
        "outputId": "c2123a3f-3d7e-4a05-f152-6daf1feb7c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "def predict_based_on_sentiment(data):\n",
        "  \"\"\"Returns a list with one value per example in data.\n",
        "\n",
        "  List values should either be 0 or 1 indicating which ending is predicted.\n",
        "  \"\"\"\n",
        "  predictions = [0] * len(data)\n",
        "  #### TODO: YOUR IMPLEMENTATION HERE ####\n",
        "  # for idx, story in enumerate(data):\n",
        "  #   options = story['options']\n",
        "  #   option_sentiments = []\n",
        "  #   for option in options:\n",
        "  #     sentiment = TextBlob(option).sentiment.polarity\n",
        "  #     option_sentiments.append(sentiment)\n",
        "  #   predictions[idx] = np.argmax(option_sentiments)\n",
        "\n",
        "  # for idx, story in enumerate(data):\n",
        "  #   context_sentences = story['context']\n",
        "  #   context_sentiment = []\n",
        "  #   for context_sentence in context_sentences:\n",
        "  #     sentiment = TextBlob(context_sentence).sentiment.polarity\n",
        "  #     context_sentiment.append(sentiment)\n",
        "  #   context_sentiment = np.mean(context_sentiment)\n",
        "  #   options = story['options']\n",
        "  #   option_sentiments = []\n",
        "  #   for option in options:\n",
        "  #     sentiment = TextBlob(option).sentiment.polarity\n",
        "  #     option_sentiments.append(sentiment)\n",
        "  #   predictions[idx] = min(range(len(option_sentiments)), \\\n",
        "  #       key = lambda i: abs(option_sentiments[i]-context_sentiment))\n",
        "\n",
        "  for idx, story in enumerate(data):\n",
        "    context_sentences = story['context']\n",
        "    fourth_sentence = context_sentences[3]\n",
        "    context_sentiment = TextBlob(fourth_sentence).sentiment.polarity\n",
        "    options = story['options']\n",
        "    option_sentiments = []\n",
        "    for option in options:\n",
        "      sentiment = TextBlob(option).sentiment.polarity\n",
        "      option_sentiments.append(sentiment)\n",
        "    predictions[idx] = min(range(len(option_sentiments)), \\\n",
        "        key = lambda i: abs(option_sentiments[i]-context_sentiment))\n",
        "  \n",
        "  return predictions\n",
        "\n",
        "predictions_valid_2016 = predict_based_on_sentiment(valid_2016_data)\n",
        "print('\\n2016 validation accuracy: ' )\n",
        "print(compute_accuracy(valid_2016_data, predictions_valid_2016))\n",
        "\n",
        "predictions_valid_2018 = predict_based_on_sentiment(valid_2018_data)\n",
        "print('\\n2018 validation accuracy: ' )\n",
        "print(compute_accuracy(valid_2018_data, predictions_valid_2018))\n",
        "\n",
        "predictions_test_2016 = predict_based_on_sentiment(test_2016_data)\n",
        "print('\\n2016 test accuracy: ' )\n",
        "print(compute_accuracy(test_2016_data, predictions_test_2016))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2016 validation accuracy: \n",
            "0.5200427578834848\n",
            "\n",
            "2018 validation accuracy: \n",
            "0.5168682367918523\n",
            "\n",
            "2016 test accuracy: \n",
            "0.5179048637092464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xsjm0sJ12Doi",
        "colab_type": "text"
      },
      "source": [
        "### Train a classifier using BERT embeddings.\n",
        "**Important: Go to `Runtime > Change runtime type` and make sure you have a GPU in your runtime before completing this section.**\n",
        "\n",
        "In this section, you'll train a classifier to predict which ending is correct. Ideally, you'd fine tune a large pre-trained language model (a.k.a. BERT) on the classification task, but since finetuning is pretty slow, we'll instead pre-compute BERT embeddings for each story context and for each possible ending. We'll then train a new model on top of these pre-computed embeddings.\n",
        "\n",
        "**But how do we do classification if the training set only contains positive examples?**\n",
        "\n",
        "We invent negative examples! At each training step, we pick a random set of 5th sentences from all of the 5th sentences in the training set to act as distractors.\n",
        "The hyperparameter `NUM_CANDIDATES` sets the number of distractors that are chosen. If `NUM_CANDIDATES` is set to 50, that means we do 50-way classification in our loss.\n",
        "\n",
        "**What should the neural network look like?**\n",
        "\n",
        "The goal of the neural network is to project the embedding of the context into the embedding space of endings. \n",
        "This way at evaluation time, we can compute a score for each candidate ending by taking the dot-product between the predicted embedding returned by the neural network and the embeddings of each ending. Whichever ending has the highest score wins.\n",
        "\n",
        "You are free to implement the neural network however you'd like, but you'll probably want to start with a simple [MLP](https://www.tensorflow.org/guide/keras/overview#sequential_model). (You'll want to omit the final softmax layer since that's taken care of for you in the train loop.)\n",
        "\n",
        "\n",
        "**What you should complete in this section:**\n",
        "* **Fill in the `get_model` function. Try at least two different architectures (varying the number of layers, hidden size, activation functions, etc.) and include a discussion of their relative performance in your report.**\n",
        "* **Try training with at least two different hyperparameter settings to see if you can improve performance. Include a discussion of the experiments you tried and their performance in your report.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo9HwvWGnUGz",
        "colab_type": "text"
      },
      "source": [
        "#### Compute/retrieve BERT embeddings.\n",
        "\n",
        "Note that we've commented out the lines to generate the BERT embeddings and instead provided you with pre-computed files since running BERT on 100k+ sequences can take a few hours.\n",
        "\n",
        "However, you are welcome to uncomment and experiment with computing the embeddings yourself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsuhEsU-L9jF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "def load_bert():\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  model = BertModel.from_pretrained('bert-base-uncased')\n",
        "  return model, tokenizer\n",
        "\n",
        "def bert_embedding(text):\n",
        "  inputs_ids = TOKENIZER.encode(text)\n",
        "  input_ids = torch.tensor(inputs_ids).unsqueeze(0)  # Batch size 1\n",
        "\n",
        "  _, merged_embedding = BERT_MODEL(input_ids)\n",
        "  return merged_embedding.detach().numpy()\n",
        "  \n",
        "def get_train_embeddings(data):\n",
        "  \"\"\"Computes embeddings for each example in the provided train set.\"\"\"\n",
        "  context_embeddings = []\n",
        "  ending_embeddings = []\n",
        "  print('Starting')\n",
        "  # for example in tqdm(data, desc='Computing BERT embeddings '):\n",
        "  for idx, example in enumerate(data):\n",
        "    if idx % 20 == 0:\n",
        "      print('{}/{}'.format(idx+1, len(data)))\n",
        "      print(' '.join(example['story']))\n",
        "    context_embedding = bert_embedding(' '.join(example['story'][:4]))\n",
        "    ending_embedding = bert_embedding(example['story'][4])\n",
        "\n",
        "    context_embeddings.append(context_embedding)\n",
        "    ending_embeddings.append(ending_embedding)\n",
        "  context_embeddings = np.concatenate(context_embeddings, axis=0)\n",
        "  ending_embeddings = np.concatenate(ending_embeddings, axis=0)\n",
        "  return context_embeddings, ending_embeddings\n",
        "\n",
        "def get_valid_embeddings(data):\n",
        "  \"\"\"Computes embeddings for each example in the provided validation set.\"\"\"\n",
        "  context_embeddings = []\n",
        "  ending_0_embeddings = []\n",
        "  ending_1_embeddings = []\n",
        "  for example in tqdm(data, desc='Computing BERT embeddings '):\n",
        "    context_embedding = bert_embedding(' '.join(example['context'][:4]))\n",
        "    ending_0_embedding = bert_embedding(example['options'][0])\n",
        "    ending_1_embedding = bert_embedding(example['options'][1])\n",
        "\n",
        "    context_embeddings.append(context_embedding)\n",
        "    ending_0_embeddings.append(ending_0_embedding)\n",
        "    ending_1_embeddings.append(ending_1_embedding)\n",
        "\n",
        "  context_embeddings = np.concatenate(context_embeddings, axis=0)\n",
        "  ending_0_embeddings = np.concatenate(ending_0_embeddings, axis=0)\n",
        "  ending_1_embeddings = np.concatenate(ending_1_embeddings, axis=0)\n",
        "  return context_embeddings, ending_0_embeddings, ending_1_embeddings\n",
        "\n",
        "# These are the lines I used to generate BERT embeddings. Since, they are slow\n",
        "# to compute, we've provided the outputs as .pkl files.\n",
        "# BERT_MODEL, TOKENIZER = load_bert()\n",
        "# train_context_embs, train_ending_embs = get_train_embeddings(train_data)\n",
        "# valid_2016_context_embs, valid_2016_ending_0_embs, valid_2016_ending_1_embs = get_valid_embeddings(valid_2016_data)\n",
        "# valid_2018_context_embs, valid_2018_ending_0_embs, valid_2018_ending_1_embs = get_valid_embeddings(valid_2018_data)\n",
        "# test_2016_context_embs, test_2016_ending_0_embs, test_2016_ending_1_embs = get_valid_embeddings(test_2018_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDP_U43qlFzv",
        "colab_type": "code",
        "outputId": "8e19072f-5628-4b33-8337-f0831da765fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!gsutil cp gs://cis700_shared_data/rocstories_data/rocstories_train.pkl /content/rocstories_train.pkl\n",
        "with open('/content/rocstories_train.pkl', 'rb') as f:\n",
        "  data = pickle.load(f)\n",
        "  train_context_embs = data['contexts']\n",
        "  train_ending_embs = data['endings']\n",
        "\n",
        "!gsutil cp gs://cis700_shared_data/rocstories_data/rocstories_valid_2016.pkl /content/rocstories_valid_2016.pkl\n",
        "with open('/content/rocstories_valid_2016.pkl', 'rb') as f:\n",
        "  data = pickle.load(f)\n",
        "  valid_2016_context_embs = data['contexts']\n",
        "  valid_2016_ending_0_embs = data['endings_0']\n",
        "  valid_2016_ending_1_embs = data['endings_1']\n",
        "\n",
        "!gsutil cp gs://cis700_shared_data/rocstories_data/rocstories_valid_2018.pkl /content/rocstories_valid_2018.pkl\n",
        "with open('/content/rocstories_valid_2018.pkl', 'rb') as f:\n",
        "  data = pickle.load(f)\n",
        "  valid_2018_context_embs = data['contexts']\n",
        "  valid_2018_ending_0_embs = data['endings_0']\n",
        "  valid_2018_ending_1_embs = data['endings_1']\n",
        "\n",
        "!gsutil cp gs://cis700_shared_data/rocstories_data/rocstories_test_2016.pkl /content/rocstories_test_2016.pkl\n",
        "with open('/content/rocstories_test_2016.pkl', 'rb') as f:\n",
        "  data = pickle.load(f)\n",
        "  test_2016_context_embs = data['contexts']\n",
        "  test_2016_ending_0_embs = data['endings_0']\n",
        "  test_2016_ending_1_embs = data['endings_1']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://cis700_shared_data/rocstories_data/rocstories_train.pkl...\n",
            "| [1 files][308.6 MiB/308.6 MiB]                                                \n",
            "Operation completed over 1 objects/308.6 MiB.                                    \n",
            "Copying gs://cis700_shared_data/rocstories_data/rocstories_valid_2016.pkl...\n",
            "/ [1 files][ 16.4 MiB/ 16.4 MiB]                                                \n",
            "Operation completed over 1 objects/16.4 MiB.                                     \n",
            "Copying gs://cis700_shared_data/rocstories_data/rocstories_valid_2018.pkl...\n",
            "/ [1 files][ 13.8 MiB/ 13.8 MiB]                                                \n",
            "Operation completed over 1 objects/13.8 MiB.                                     \n",
            "Copying gs://cis700_shared_data/rocstories_data/rocstories_test_2016.pkl...\n",
            "/ [1 files][ 16.4 MiB/ 16.4 MiB]                                                \n",
            "Operation completed over 1 objects/16.4 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWBaQAX-rosb",
        "colab_type": "text"
      },
      "source": [
        "#### Train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Cile0a0xrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(batch_size, num_candidates):\n",
        "  \"\"\"Returns a single training batch.\n",
        "  \n",
        "  Returns:\n",
        "  batch_inputs: [batch_size, embedding_size] matrix of context embeddings.\n",
        "  batch_candidates: [num_candidates, embedding_size] matrix of embeddings of \n",
        "    candidate 5th sentence embeddings. The groundtruth 5th sentence for the ith\n",
        "    example in batch_inputs is in the ith row of batch_candidates.\n",
        "  labels: [batch_size] For each example in batch_inputs, the index of the true\n",
        "    5th sentence in batch_candidates.\n",
        "  \"\"\"\n",
        "  if num_candidates < batch_size:\n",
        "    raise ValueError(\n",
        "        'At minimum the number of candidates is at least all of the other 5th '\n",
        "        'sentences in the batch.')\n",
        "    \n",
        "  batch_inputs = []\n",
        "  batch_candidates = []\n",
        "  batch_labels = []\n",
        "  for i in range(batch_size):\n",
        "    rand_ex_index = random.randint(0, train_context_embs.shape[0]-1)\n",
        "    batch_inputs.append(train_context_embs[rand_ex_index, :])\n",
        "    batch_candidates.append(train_ending_embs[rand_ex_index, :])\n",
        "    # The true next embedding is in the ith position in the candidates\n",
        "    batch_labels.append(i)\n",
        "\n",
        "  # Increase the number of \"distractor\" candidates to num_candidates.\n",
        "  for i in range(num_candidates - batch_size):\n",
        "    rand_ex_index = random.randint(0, train_context_embs.shape[0]-1)\n",
        "    batch_candidates.append(train_ending_embs[rand_ex_index, :])\n",
        "\n",
        "  batch_inputs = np.stack(batch_inputs, axis=0)\n",
        "  batch_candidates = np.stack(batch_candidates, axis=0)\n",
        "  return batch_inputs, batch_candidates, batch_labels\n",
        "\n",
        "def predict_based_on_bert_classifier(\n",
        "    context_embs, ending_0_embs, ending_1_embs, model):\n",
        "  \"\"\"Returns a list of predictions based on model.\"\"\"\n",
        "  predicted_embs = model(context_embs)\n",
        "  \n",
        "  predictions = []\n",
        "  for idx in range(predicted_embs.shape[0]):\n",
        "    pred_emb = predicted_embs[idx, :]\n",
        "    score_0 = np.dot(pred_emb, ending_0_embs[idx, :])\n",
        "    score_1 = np.dot(pred_emb, ending_1_embs[idx, :])\n",
        "    predictions.append(score_0 < score_1)\n",
        "  return predictions\n",
        "  \n",
        "def get_model():\n",
        "  \"\"\"Returns a Keras model.\n",
        "  The model should input a [batch_size, embedding_size] tensor and output a new\n",
        "  [batch_size, embedding_size] tensor. At it's simplest, it could just be a\n",
        "  single dense layer. You should experiment with adding layers, changing the\n",
        "  activation function, or otherwise modifying the architecture defined below.\n",
        "  See:\n",
        "  https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  # This is an example of a very simple network consisting of a single nonlinear\n",
        "  # layer followed by a linear projection back to the BERT embedding size.\n",
        "  # model = tf.keras.Sequential()\n",
        "  # model.add(tf.keras.layers.Dense(512, activation=\"relu\"))\n",
        "  # model.add(tf.keras.layers.Dense(768, activation=\"linear\"))\n",
        "\n",
        "  # # Alternative Model 1\n",
        "  # model = tf.keras.Sequential()\n",
        "  # model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dense(768, activation='relu'))\n",
        "\n",
        "  # # Alternative Model 2\n",
        "  # model = tf.keras.Sequential()\n",
        "  # model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "  # model.add(tf.keras.layers.Dense(256, activation='tanh'))\n",
        "  # model.add(tf.keras.layers.Dense(768, activation='relu'))\n",
        "\n",
        "  # Alternative Model 3\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(256, activation='softplus'))\n",
        "  model.add(tf.keras.layers.Dense(768, activation='relu'))\n",
        "\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-v8K2mDiuFO",
        "colab_type": "text"
      },
      "source": [
        "You should experiment with the hyperparamters (IN ALL_CAPS) below to see if you can improve performance. I was able to get 67% validation accuracy with the provided values and using a two-layer network with a ReLU nonlinearity between the layers. Training took about an hour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i38yZvqkZIj3",
        "colab_type": "code",
        "outputId": "837294c9-59f5-4513-97e7-14816042826c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#### HYPERPARAMETERS ####\n",
        "NUM_TRAIN_STEPS = 10000  # How many step to train for.\n",
        "BATCH_SIZE = 32  # Number of examples used in step of training.\n",
        "NUM_CANDIDATES = 50  # Number of candidate 5th sentences classifier must decide between.\n",
        "LEARNING_RATE = 0.001  # Learning rate.\n",
        "# If your loss is barely going down, learning rate might be too small.\n",
        "# If your loss is jumping around, it might be too big.\n",
        "\n",
        "# You may experiment with other optimizers or loss functions if you'd like.\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model = get_model()\n",
        "\n",
        "# Iterate over the batches of a dataset.\n",
        "for train_step in range(NUM_TRAIN_STEPS):\n",
        "  with tf.GradientTape() as tape:\n",
        "    batch_inputs, batch_candidates, batch_labels = get_batch(BATCH_SIZE, NUM_CANDIDATES)\n",
        "\n",
        "    # Predicted 5th sentence embedding for each batch position/\n",
        "    outputs = model(batch_inputs)\n",
        "    # The logits will be batch_size * num_candidates, giving a score for each\n",
        "    # candidate 5th sentence. We'd like the true 5th sentence to have the\n",
        "    # highest score.\n",
        "    logits = tf.matmul(outputs, batch_candidates, transpose_b=True)\n",
        "    # Loss value for this minibatch\n",
        "    loss_value = loss_fn(batch_labels, logits)\n",
        "\n",
        "  grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "  if train_step % 100 == 0:\n",
        "    print('Step {}, batch_train_loss={}'.format(train_step, loss_value))\n",
        "  if train_step % 1000 == 0:\n",
        "    predictions_2016 = predict_based_on_bert_classifier(valid_2016_context_embs, valid_2016_ending_0_embs, valid_2016_ending_1_embs,model)\n",
        "    predictions_2018 = predict_based_on_bert_classifier(valid_2018_context_embs, valid_2018_ending_0_embs, valid_2018_ending_1_embs,model)\n",
        "    \n",
        "    print('2016 validation accuracy: {}'.format(compute_accuracy(valid_2016_data, predictions_2016)))\n",
        "    print('2018 validation accuracy: {}'.format(compute_accuracy(valid_2018_data, predictions_2018)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, batch_train_loss=5.215843200683594\n",
            "2016 validation accuracy: 0.4965259219668626\n",
            "2018 validation accuracy: 0.4945894334818587\n",
            "Step 100, batch_train_loss=3.901401996612549\n",
            "Step 200, batch_train_loss=3.8299901485443115\n",
            "Step 300, batch_train_loss=3.5799036026000977\n",
            "Step 400, batch_train_loss=3.3779428005218506\n",
            "Step 500, batch_train_loss=3.451571226119995\n",
            "Step 600, batch_train_loss=3.1816306114196777\n",
            "Step 700, batch_train_loss=3.3197991847991943\n",
            "Step 800, batch_train_loss=3.4093098640441895\n",
            "Step 900, batch_train_loss=3.1590561866760254\n",
            "Step 1000, batch_train_loss=3.2010788917541504\n",
            "2016 validation accuracy: 0.4927846071619455\n",
            "2018 validation accuracy: 0.486950986632718\n",
            "Step 1100, batch_train_loss=2.9052600860595703\n",
            "Step 1200, batch_train_loss=2.8513431549072266\n",
            "Step 1300, batch_train_loss=2.9681410789489746\n",
            "Step 1400, batch_train_loss=2.866698980331421\n",
            "Step 1500, batch_train_loss=3.1214287281036377\n",
            "Step 1600, batch_train_loss=2.6446709632873535\n",
            "Step 1700, batch_train_loss=2.7246756553649902\n",
            "Step 1800, batch_train_loss=2.724658727645874\n",
            "Step 1900, batch_train_loss=2.917130708694458\n",
            "Step 2000, batch_train_loss=2.8588361740112305\n",
            "2016 validation accuracy: 0.5649385355424906\n",
            "2018 validation accuracy: 0.5595162316995544\n",
            "Step 2100, batch_train_loss=2.9518251419067383\n",
            "Step 2200, batch_train_loss=2.7997307777404785\n",
            "Step 2300, batch_train_loss=2.6799020767211914\n",
            "Step 2400, batch_train_loss=3.04317569732666\n",
            "Step 2500, batch_train_loss=2.6747169494628906\n",
            "Step 2600, batch_train_loss=2.5842061042785645\n",
            "Step 2700, batch_train_loss=2.5725820064544678\n",
            "Step 2800, batch_train_loss=2.6246583461761475\n",
            "Step 2900, batch_train_loss=2.6331589221954346\n",
            "Step 3000, batch_train_loss=2.669955253601074\n",
            "2016 validation accuracy: 0.6119722073757349\n",
            "2018 validation accuracy: 0.6136218968809676\n",
            "Step 3100, batch_train_loss=2.8415002822875977\n",
            "Step 3200, batch_train_loss=2.6156821250915527\n",
            "Step 3300, batch_train_loss=2.783215284347534\n",
            "Step 3400, batch_train_loss=2.9821343421936035\n",
            "Step 3500, batch_train_loss=2.883051872253418\n",
            "Step 3600, batch_train_loss=2.5041985511779785\n",
            "Step 3700, batch_train_loss=2.5960657596588135\n",
            "Step 3800, batch_train_loss=3.2321224212646484\n",
            "Step 3900, batch_train_loss=2.3553407192230225\n",
            "Step 4000, batch_train_loss=2.8319571018218994\n",
            "2016 validation accuracy: 0.6173169428113309\n",
            "2018 validation accuracy: 0.6155315085932527\n",
            "Step 4100, batch_train_loss=2.8474926948547363\n",
            "Step 4200, batch_train_loss=2.6023149490356445\n",
            "Step 4300, batch_train_loss=2.1916565895080566\n",
            "Step 4400, batch_train_loss=2.6973111629486084\n",
            "Step 4500, batch_train_loss=2.7812161445617676\n",
            "Step 4600, batch_train_loss=2.248444080352783\n",
            "Step 4700, batch_train_loss=2.3869099617004395\n",
            "Step 4800, batch_train_loss=2.909597158432007\n",
            "Step 4900, batch_train_loss=2.658280372619629\n",
            "Step 5000, batch_train_loss=2.6031298637390137\n",
            "2016 validation accuracy: 0.6392303580972741\n",
            "2018 validation accuracy: 0.6384468491406747\n",
            "Step 5100, batch_train_loss=2.0280823707580566\n",
            "Step 5200, batch_train_loss=2.462951183319092\n",
            "Step 5300, batch_train_loss=2.5372934341430664\n",
            "Step 5400, batch_train_loss=2.5528576374053955\n",
            "Step 5500, batch_train_loss=2.6004467010498047\n",
            "Step 5600, batch_train_loss=2.2571845054626465\n",
            "Step 5700, batch_train_loss=2.3829398155212402\n",
            "Step 5800, batch_train_loss=2.201691150665283\n",
            "Step 5900, batch_train_loss=2.6838271617889404\n",
            "Step 6000, batch_train_loss=2.501248836517334\n",
            "2016 validation accuracy: 0.6344200962052379\n",
            "2018 validation accuracy: 0.6397199236155315\n",
            "Step 6100, batch_train_loss=2.912738800048828\n",
            "Step 6200, batch_train_loss=2.2772376537323\n",
            "Step 6300, batch_train_loss=2.2961578369140625\n",
            "Step 6400, batch_train_loss=2.22084379196167\n",
            "Step 6500, batch_train_loss=2.56626558303833\n",
            "Step 6600, batch_train_loss=2.6051459312438965\n",
            "Step 6700, batch_train_loss=2.4958391189575195\n",
            "Step 6800, batch_train_loss=2.523606777191162\n",
            "Step 6900, batch_train_loss=1.903268814086914\n",
            "Step 7000, batch_train_loss=2.7277958393096924\n",
            "2016 validation accuracy: 0.6440406199893105\n",
            "2018 validation accuracy: 0.6441756842775302\n",
            "Step 7100, batch_train_loss=2.202507257461548\n",
            "Step 7200, batch_train_loss=2.8275980949401855\n",
            "Step 7300, batch_train_loss=2.220693588256836\n",
            "Step 7400, batch_train_loss=2.785773754119873\n",
            "Step 7500, batch_train_loss=2.4150009155273438\n",
            "Step 7600, batch_train_loss=2.2719879150390625\n",
            "Step 7700, batch_train_loss=2.5766446590423584\n",
            "Step 7800, batch_train_loss=2.512843132019043\n",
            "Step 7900, batch_train_loss=2.5584299564361572\n",
            "Step 8000, batch_train_loss=2.18196702003479\n",
            "2016 validation accuracy: 0.6493853554249065\n",
            "2018 validation accuracy: 0.6543602800763845\n",
            "Step 8100, batch_train_loss=2.0900979042053223\n",
            "Step 8200, batch_train_loss=2.583301067352295\n",
            "Step 8300, batch_train_loss=2.552445888519287\n",
            "Step 8400, batch_train_loss=2.5803704261779785\n",
            "Step 8500, batch_train_loss=2.468688488006592\n",
            "Step 8600, batch_train_loss=2.3142685890197754\n",
            "Step 8700, batch_train_loss=2.26580548286438\n",
            "Step 8800, batch_train_loss=2.157255172729492\n",
            "Step 8900, batch_train_loss=1.8530521392822266\n",
            "Step 9000, batch_train_loss=2.302173614501953\n",
            "2016 validation accuracy: 0.6451095670764297\n",
            "2018 validation accuracy: 0.6492679821769574\n",
            "Step 9100, batch_train_loss=2.2563161849975586\n",
            "Step 9200, batch_train_loss=2.292914628982544\n",
            "Step 9300, batch_train_loss=2.3146462440490723\n",
            "Step 9400, batch_train_loss=2.03497576713562\n",
            "Step 9500, batch_train_loss=2.3910508155822754\n",
            "Step 9600, batch_train_loss=2.364165782928467\n",
            "Step 9700, batch_train_loss=2.2291104793548584\n",
            "Step 9800, batch_train_loss=2.0543956756591797\n",
            "Step 9900, batch_train_loss=1.9631612300872803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7gyObIurdVQ",
        "colab_type": "text"
      },
      "source": [
        "**What is overfitting?**\n",
        "\n",
        "You may have observed when training that your validation accuracy goes up for a while and then eventually starts going down. This is called overfitting, because your model is learning to be really good at classifying examples from the training set at the expense of dong a good job at classifying usneen exampes in the validation set. You could prevent overfitting by automatically stopping training when the validation accuracy has not improved in X steps (where X is another hyperparamter you'd have to decide upon)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMjv10QFrdnd",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EZCCuQLRcEI",
        "colab_type": "code",
        "outputId": "dee9bff6-677e-432e-f884-732e323dde7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "predictions_2016 = predict_based_on_bert_classifier(\n",
        "    valid_2016_context_embs, valid_2016_ending_0_embs, valid_2016_ending_1_embs,\n",
        "    model)\n",
        "print('\\n2016 validation accuracy: ' )\n",
        "print(compute_accuracy(valid_2016_data, predictions_2016))\n",
        "\n",
        "predictions_2018 = predict_based_on_bert_classifier(\n",
        "    valid_2018_context_embs, valid_2018_ending_0_embs, valid_2018_ending_1_embs,\n",
        "    model)\n",
        "print('\\n2018 validation accuracy: ' )\n",
        "print(compute_accuracy(valid_2018_data, predictions_2018))\n",
        "\n",
        "predictions_2016 = predict_based_on_bert_classifier(\n",
        "    test_2016_context_embs, test_2016_ending_0_embs, test_2016_ending_1_embs,\n",
        "    model)\n",
        "print('\\n2016 test accuracy: ' )\n",
        "print(compute_accuracy(test_2016_data, predictions_2016))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2016 validation accuracy: \n",
            "0.6477819347942276\n",
            "\n",
            "2018 validation accuracy: \n",
            "0.648631444939529\n",
            "\n",
            "2016 test accuracy: \n",
            "0.6247995724211651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw0LAKC9O9zy",
        "colab_type": "text"
      },
      "source": [
        "### Train classifier on validation set\n",
        "Part of the difficulty (and interestingness) of the ROCStories task is that the training set contains only positive examples. However, researchers have found that accuracies as high as 90% are possible if you cheat and train a supervised classifier using the examples with both positive and negative examples found in the validation set.\n",
        "\n",
        "**Run the train code below, experimenting with at least twos variant, either modifying the hyperparamters or model architecture. You could also try to find a way to take advantage of the large unlabeled dataset in addition to the labeled data. Include a discussion in your report.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enNKm3zYnwba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch_from_valid(batch_size, inputs, labels):\n",
        "  \"\"\"Returns a single training batch extracted form the validation set.\n",
        "\n",
        "  Inputs:\n",
        "  batch_size: The batch size.\n",
        "  inputs: [dataset_size, 2*embedding_size] matrix of all inputs in the training\n",
        "    set.\n",
        "  labels: [dataset_size] for each example, 0 if example has the incorrect ending\n",
        "    embedding, 1 if it has the correct ending embedding.\n",
        "  \n",
        "  Returns:\n",
        "  batch_inputs: [batch_size, 2*embedding_size] matrix of embeddings (each\n",
        "    embedding is a context embedding concatenated with an ending embedding).\n",
        "  labels: [batch_size] For each example in batch_inputs, contains either 0 or 1,\n",
        "    indicating whether the 5th ending is the correct one.\n",
        "  \"\"\"\n",
        "  batch_inputs = []\n",
        "  batch_labels = []\n",
        "  for i in range(batch_size):\n",
        "    rand_ex_index = random.randint(0, inputs.shape[0]-1)    \n",
        "    batch_inputs.append(inputs[rand_ex_index, :])\n",
        "    batch_labels.append(labels[rand_ex_index])\n",
        "    \n",
        "  batch_inputs = np.stack(batch_inputs, axis=0)\n",
        "  return batch_inputs, batch_labels\n",
        "\n",
        "# Each input example consists of a context_embedding concatenated with an ending embedding.\n",
        "def build_dataset():\n",
        "  \"\"\"Builds a dataset out of the validation set examples.\n",
        "\n",
        "  Each example in valid_2016 and valid_2018 becomes two exampes in this new \n",
        "  dataset:\n",
        "  * one where ending_0's embedding is concatenated to the context embedding\n",
        "  * one where ending_1's embedding is concatenated to the context embedding\n",
        "\n",
        "  The label for each example is 1 if the correct ending's embedding is present,\n",
        "  0 if the incorrect ending's embedding is present.\n",
        "\n",
        "  Returns:\n",
        "  all_inputs: [new_dataset_size, embedding_size*2]\n",
        "  all_labels: [new_dataset_size]\n",
        "  \"\"\"\n",
        "  inputs_2016 = tf.concat(\n",
        "      [tf.concat([valid_2016_context_embs, valid_2016_ending_0_embs], axis=-1),\n",
        "      tf.concat([valid_2016_context_embs, valid_2016_ending_1_embs], axis=-1)], axis=0)\n",
        "  labels = [ex['label'] for ex in valid_2016_data]\n",
        "  labels_2016 = labels + [1 - label for label in labels]\n",
        "\n",
        "  inputs_2018 = tf.concat(\n",
        "      [tf.concat([valid_2018_context_embs, valid_2018_ending_0_embs], axis=-1),\n",
        "      tf.concat([valid_2018_context_embs, valid_2018_ending_1_embs], axis=-1)], axis=0)\n",
        "  labels = [ex['label'] for ex in valid_2018_data]\n",
        "  labels_2018 = labels + [1 - label for label in labels]\n",
        "\n",
        "  all_inputs = tf.concat([inputs_2016, inputs_2018], axis=0)\n",
        "  all_labels = labels_2016 + labels_2018\n",
        "\n",
        "  return all_inputs, all_labels\n",
        "\n",
        "def predict_based_on_bert_binary_classifier(\n",
        "    context_embs, ending_0_embs, ending_1_embs, model):\n",
        "  \"\"\"Returns a list of predictions based on binary classification model.\"\"\"\n",
        "  scores_ending_0 = model(tf.concat([context_embs, ending_0_embs], -1))\n",
        "  scores_ending_1 = model(tf.concat([context_embs, ending_1_embs], -1))\n",
        "  predictions = tf.greater(scores_ending_0, scores_ending_1)[:, 1]\n",
        "  return predictions\n",
        "\n",
        "def get_binary_classifier():\n",
        "  \"\"\"Returns a Keras model.\n",
        "  The model should input a [batch_size, 2*embedding_size] tensor and output a\n",
        "  [batch_size, 2] tensor. The final final dimension needs to be 2 because we are\n",
        "  doing binary classification.\n",
        "  \n",
        "  You should experiment with modifying the architecture below.\n",
        "  See:\n",
        "  https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  # model = tf.keras.Sequential()\n",
        "  # model.add(tf.keras.layers.Dense(512, activation=\"relu\"))\n",
        "  # model.add(tf.keras.layers.Dense(2, activation=\"linear\"))\n",
        "\n",
        "  # Variant 1\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(256, activation='softplus'))\n",
        "  model.add(tf.keras.layers.Dense(2, activation=\"linear\"))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gcXfLYUL5Mc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae9b93f6-7768-4f34-908e-102272ca83b2"
      },
      "source": [
        "NUM_TRAIN_STEPS = 20000  # How many step to train for.\n",
        "BATCH_SIZE = 32  # Number of examples used in step of training.\n",
        "LEARNING_RATE = 0.001  # Learning rate.\n",
        "\n",
        "NUM_TRAIN_EXAMPLES = 2500 # How many examples from the valid set to use for training.\n",
        "# NUM_TRAIN_EXAMPLES = 7500 # How many examples from the valid set to use for training.\n",
        "# The remainder will be placed into a new valid set.\n",
        "\n",
        "# You should with varying NUM_TRAIN_EXAMPLES. If it is larger, you will train a \n",
        "# better model, but you will have fewer examples available your validation set\n",
        "# for tuning other hyperparameters.\n",
        "all_inputs, all_labels = build_dataset()\n",
        "train_inputs = all_inputs[:NUM_TRAIN_EXAMPLES, :]\n",
        "train_labels = all_labels[:NUM_TRAIN_EXAMPLES]\n",
        "valid_inputs = all_inputs[NUM_TRAIN_EXAMPLES:, :]\n",
        "valid_labels = all_labels[NUM_TRAIN_EXAMPLES:]\n",
        "\n",
        "# You may experiment with other optimizers or loss functions if you'd like.\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model_2 = get_binary_classifier()\n",
        "\n",
        "# Iterate over the batches of a dataset.\n",
        "for train_step in range(NUM_TRAIN_STEPS):\n",
        "  with tf.GradientTape() as tape:\n",
        "    batch_inputs, batch_labels = get_batch_from_valid(\n",
        "        BATCH_SIZE, train_inputs, train_labels)\n",
        "\n",
        "    logits = model_2(batch_inputs)\n",
        "    loss_value = loss_fn(batch_labels, logits)\n",
        "\n",
        "  grads = tape.gradient(loss_value, model_2.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(grads, model_2.trainable_weights))\n",
        "\n",
        "  if train_step % 100 == 0:\n",
        "    batch_acc = sum(tf.equal(batch_labels, tf.argmax(logits, axis=-1)).numpy()) / BATCH_SIZE\n",
        "    print('Step {0}, batch_loss={1:.5f}, batch_acc={2:.3f}'.format(\n",
        "        train_step, loss_value, batch_acc))\n",
        "  if train_step % 1000 == 0:\n",
        "    valid_logits = model_2(valid_inputs)\n",
        "    num_correct = sum(tf.equal(valid_labels, tf.argmax(valid_logits, axis=-1)).numpy())\n",
        "    print('Validation accuracy: {0:.3f}'.format(num_correct / len(valid_labels)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, batch_loss=0.64501, batch_acc=0.719\n",
            "Validation accuracy: 0.492\n",
            "Step 100, batch_loss=0.67284, batch_acc=0.594\n",
            "Step 200, batch_loss=0.67962, batch_acc=0.594\n",
            "Step 300, batch_loss=0.70239, batch_acc=0.500\n",
            "Step 400, batch_loss=0.68914, batch_acc=0.625\n",
            "Step 500, batch_loss=0.68558, batch_acc=0.625\n",
            "Step 600, batch_loss=0.69053, batch_acc=0.531\n",
            "Step 700, batch_loss=0.69453, batch_acc=0.469\n",
            "Step 800, batch_loss=0.70224, batch_acc=0.500\n",
            "Step 900, batch_loss=0.71293, batch_acc=0.438\n",
            "Step 1000, batch_loss=0.69050, batch_acc=0.562\n",
            "Validation accuracy: 0.492\n",
            "Step 1100, batch_loss=0.66326, batch_acc=0.594\n",
            "Step 1200, batch_loss=0.69090, batch_acc=0.562\n",
            "Step 1300, batch_loss=0.68850, batch_acc=0.562\n",
            "Step 1400, batch_loss=0.70231, batch_acc=0.500\n",
            "Step 1500, batch_loss=0.65959, batch_acc=0.656\n",
            "Step 1600, batch_loss=0.67639, batch_acc=0.594\n",
            "Step 1700, batch_loss=0.67185, batch_acc=0.531\n",
            "Step 1800, batch_loss=0.67548, batch_acc=0.594\n",
            "Step 1900, batch_loss=0.69960, batch_acc=0.406\n",
            "Step 2000, batch_loss=0.68971, batch_acc=0.625\n",
            "Validation accuracy: 0.508\n",
            "Step 2100, batch_loss=0.74268, batch_acc=0.500\n",
            "Step 2200, batch_loss=0.70015, batch_acc=0.500\n",
            "Step 2300, batch_loss=0.69350, batch_acc=0.500\n",
            "Step 2400, batch_loss=0.66829, batch_acc=0.656\n",
            "Step 2500, batch_loss=0.70538, batch_acc=0.531\n",
            "Step 2600, batch_loss=0.67552, batch_acc=0.594\n",
            "Step 2700, batch_loss=0.66415, batch_acc=0.625\n",
            "Step 2800, batch_loss=0.69100, batch_acc=0.562\n",
            "Step 2900, batch_loss=0.69284, batch_acc=0.531\n",
            "Step 3000, batch_loss=0.67507, batch_acc=0.469\n",
            "Validation accuracy: 0.494\n",
            "Step 3100, batch_loss=0.73762, batch_acc=0.344\n",
            "Step 3200, batch_loss=0.66231, batch_acc=0.625\n",
            "Step 3300, batch_loss=0.68237, batch_acc=0.594\n",
            "Step 3400, batch_loss=0.71452, batch_acc=0.438\n",
            "Step 3500, batch_loss=0.69136, batch_acc=0.531\n",
            "Step 3600, batch_loss=0.74143, batch_acc=0.375\n",
            "Step 3700, batch_loss=0.69820, batch_acc=0.406\n",
            "Step 3800, batch_loss=0.70743, batch_acc=0.469\n",
            "Step 3900, batch_loss=0.71440, batch_acc=0.344\n",
            "Step 4000, batch_loss=0.69666, batch_acc=0.344\n",
            "Validation accuracy: 0.492\n",
            "Step 4100, batch_loss=0.68585, batch_acc=0.562\n",
            "Step 4200, batch_loss=0.70989, batch_acc=0.406\n",
            "Step 4300, batch_loss=0.67754, batch_acc=0.625\n",
            "Step 4400, batch_loss=0.74190, batch_acc=0.375\n",
            "Step 4500, batch_loss=0.71712, batch_acc=0.469\n",
            "Step 4600, batch_loss=0.72499, batch_acc=0.469\n",
            "Step 4700, batch_loss=0.69792, batch_acc=0.500\n",
            "Step 4800, batch_loss=0.71458, batch_acc=0.406\n",
            "Step 4900, batch_loss=0.69322, batch_acc=0.500\n",
            "Step 5000, batch_loss=0.75179, batch_acc=0.375\n",
            "Validation accuracy: 0.507\n",
            "Step 5100, batch_loss=0.67600, batch_acc=0.594\n",
            "Step 5200, batch_loss=0.68325, batch_acc=0.594\n",
            "Step 5300, batch_loss=0.66477, batch_acc=0.625\n",
            "Step 5400, batch_loss=0.69386, batch_acc=0.438\n",
            "Step 5500, batch_loss=0.66422, batch_acc=0.625\n",
            "Step 5600, batch_loss=0.68692, batch_acc=0.594\n",
            "Step 5700, batch_loss=0.69343, batch_acc=0.562\n",
            "Step 5800, batch_loss=0.68124, batch_acc=0.594\n",
            "Step 5900, batch_loss=0.71352, batch_acc=0.469\n",
            "Step 6000, batch_loss=0.69673, batch_acc=0.469\n",
            "Validation accuracy: 0.493\n",
            "Step 6100, batch_loss=0.72501, batch_acc=0.344\n",
            "Step 6200, batch_loss=0.72850, batch_acc=0.312\n",
            "Step 6300, batch_loss=0.72038, batch_acc=0.375\n",
            "Step 6400, batch_loss=0.68885, batch_acc=0.562\n",
            "Step 6500, batch_loss=0.67577, batch_acc=0.594\n",
            "Step 6600, batch_loss=0.69385, batch_acc=0.500\n",
            "Step 6700, batch_loss=0.66733, batch_acc=0.562\n",
            "Step 6800, batch_loss=0.69515, batch_acc=0.500\n",
            "Step 6900, batch_loss=0.69151, batch_acc=0.531\n",
            "Step 7000, batch_loss=0.73336, batch_acc=0.375\n",
            "Validation accuracy: 0.507\n",
            "Step 7100, batch_loss=0.69918, batch_acc=0.531\n",
            "Step 7200, batch_loss=0.67745, batch_acc=0.594\n",
            "Step 7300, batch_loss=0.76925, batch_acc=0.406\n",
            "Step 7400, batch_loss=0.69250, batch_acc=0.562\n",
            "Step 7500, batch_loss=0.68673, batch_acc=0.562\n",
            "Step 7600, batch_loss=0.67311, batch_acc=0.531\n",
            "Step 7700, batch_loss=0.81853, batch_acc=0.344\n",
            "Step 7800, batch_loss=0.69711, batch_acc=0.500\n",
            "Step 7900, batch_loss=0.66959, batch_acc=0.562\n",
            "Step 8000, batch_loss=0.68749, batch_acc=0.406\n",
            "Validation accuracy: 0.492\n",
            "Step 8100, batch_loss=0.69121, batch_acc=0.531\n",
            "Step 8200, batch_loss=0.70072, batch_acc=0.500\n",
            "Step 8300, batch_loss=0.69330, batch_acc=0.500\n",
            "Step 8400, batch_loss=0.67091, batch_acc=0.688\n",
            "Step 8500, batch_loss=0.67816, batch_acc=0.500\n",
            "Step 8600, batch_loss=0.72302, batch_acc=0.438\n",
            "Step 8700, batch_loss=0.75057, batch_acc=0.531\n",
            "Step 8800, batch_loss=0.69407, batch_acc=0.469\n",
            "Step 8900, batch_loss=0.71310, batch_acc=0.375\n",
            "Step 9000, batch_loss=0.68070, batch_acc=0.594\n",
            "Validation accuracy: 0.508\n",
            "Step 9100, batch_loss=0.69804, batch_acc=0.406\n",
            "Step 9200, batch_loss=0.69034, batch_acc=0.562\n",
            "Step 9300, batch_loss=0.68652, batch_acc=0.562\n",
            "Step 9400, batch_loss=0.68514, batch_acc=0.594\n",
            "Step 9500, batch_loss=0.65810, batch_acc=0.688\n",
            "Step 9600, batch_loss=0.70225, batch_acc=0.312\n",
            "Step 9700, batch_loss=0.69685, batch_acc=0.438\n",
            "Step 9800, batch_loss=0.70465, batch_acc=0.438\n",
            "Step 9900, batch_loss=0.69629, batch_acc=0.531\n",
            "Step 10000, batch_loss=0.69150, batch_acc=0.531\n",
            "Validation accuracy: 0.507\n",
            "Step 10100, batch_loss=0.69499, batch_acc=0.375\n",
            "Step 10200, batch_loss=0.70763, batch_acc=0.438\n",
            "Step 10300, batch_loss=0.69480, batch_acc=0.500\n",
            "Step 10400, batch_loss=0.68690, batch_acc=0.562\n",
            "Step 10500, batch_loss=0.70013, batch_acc=0.500\n",
            "Step 10600, batch_loss=0.69783, batch_acc=0.469\n",
            "Step 10700, batch_loss=0.70776, batch_acc=0.406\n",
            "Step 10800, batch_loss=0.64233, batch_acc=0.750\n",
            "Step 10900, batch_loss=0.69463, batch_acc=0.500\n",
            "Step 11000, batch_loss=0.71176, batch_acc=0.406\n",
            "Validation accuracy: 0.508\n",
            "Step 11100, batch_loss=0.71217, batch_acc=0.375\n",
            "Step 11200, batch_loss=0.67433, batch_acc=0.500\n",
            "Step 11300, batch_loss=0.69202, batch_acc=0.531\n",
            "Step 11400, batch_loss=0.69769, batch_acc=0.438\n",
            "Step 11500, batch_loss=0.68673, batch_acc=0.562\n",
            "Step 11600, batch_loss=0.69367, batch_acc=0.500\n",
            "Step 11700, batch_loss=0.62823, batch_acc=0.719\n",
            "Step 11800, batch_loss=0.62311, batch_acc=0.719\n",
            "Step 11900, batch_loss=0.67651, batch_acc=0.500\n",
            "Step 12000, batch_loss=0.69421, batch_acc=0.469\n",
            "Validation accuracy: 0.508\n",
            "Step 12100, batch_loss=0.66727, batch_acc=0.562\n",
            "Step 12200, batch_loss=0.69955, batch_acc=0.500\n",
            "Step 12300, batch_loss=0.69157, batch_acc=0.531\n",
            "Step 12400, batch_loss=0.73223, batch_acc=0.438\n",
            "Step 12500, batch_loss=0.69782, batch_acc=0.500\n",
            "Step 12600, batch_loss=0.69451, batch_acc=0.344\n",
            "Step 12700, batch_loss=0.69745, batch_acc=0.469\n",
            "Step 12800, batch_loss=0.71860, batch_acc=0.531\n",
            "Step 12900, batch_loss=0.69867, batch_acc=0.500\n",
            "Step 13000, batch_loss=0.69126, batch_acc=0.531\n",
            "Validation accuracy: 0.493\n",
            "Step 13100, batch_loss=0.70486, batch_acc=0.531\n",
            "Step 13200, batch_loss=0.67939, batch_acc=0.500\n",
            "Step 13300, batch_loss=0.67973, batch_acc=0.594\n",
            "Step 13400, batch_loss=0.69632, batch_acc=0.469\n",
            "Step 13500, batch_loss=0.72197, batch_acc=0.438\n",
            "Step 13600, batch_loss=0.69966, batch_acc=0.469\n",
            "Step 13700, batch_loss=0.68459, batch_acc=0.594\n",
            "Step 13800, batch_loss=0.68723, batch_acc=0.594\n",
            "Step 13900, batch_loss=0.70006, batch_acc=0.438\n",
            "Step 14000, batch_loss=0.67317, batch_acc=0.625\n",
            "Validation accuracy: 0.492\n",
            "Step 14100, batch_loss=0.69064, batch_acc=0.562\n",
            "Step 14200, batch_loss=0.69462, batch_acc=0.531\n",
            "Step 14300, batch_loss=0.68533, batch_acc=0.562\n",
            "Step 14400, batch_loss=0.69473, batch_acc=0.469\n",
            "Step 14500, batch_loss=0.64994, batch_acc=0.562\n",
            "Step 14600, batch_loss=0.68801, batch_acc=0.469\n",
            "Step 14700, batch_loss=0.69315, batch_acc=0.406\n",
            "Step 14800, batch_loss=0.69716, batch_acc=0.500\n",
            "Step 14900, batch_loss=0.70542, batch_acc=0.562\n",
            "Step 15000, batch_loss=0.72716, batch_acc=0.406\n",
            "Validation accuracy: 0.507\n",
            "Step 15100, batch_loss=0.65796, batch_acc=0.656\n",
            "Step 15200, batch_loss=0.68088, batch_acc=0.594\n",
            "Step 15300, batch_loss=0.69562, batch_acc=0.438\n",
            "Step 15400, batch_loss=0.68681, batch_acc=0.562\n",
            "Step 15500, batch_loss=0.68486, batch_acc=0.625\n",
            "Step 15600, batch_loss=0.67131, batch_acc=0.625\n",
            "Step 15700, batch_loss=0.71857, batch_acc=0.312\n",
            "Step 15800, batch_loss=0.69392, batch_acc=0.438\n",
            "Step 15900, batch_loss=0.68776, batch_acc=0.625\n",
            "Step 16000, batch_loss=0.66887, batch_acc=0.562\n",
            "Validation accuracy: 0.492\n",
            "Step 16100, batch_loss=0.69232, batch_acc=0.625\n",
            "Step 16200, batch_loss=0.63711, batch_acc=0.719\n",
            "Step 16300, batch_loss=0.68879, batch_acc=0.562\n",
            "Step 16400, batch_loss=0.74321, batch_acc=0.344\n",
            "Step 16500, batch_loss=0.71060, batch_acc=0.406\n",
            "Step 16600, batch_loss=0.67386, batch_acc=0.625\n",
            "Step 16700, batch_loss=0.69140, batch_acc=0.531\n",
            "Step 16800, batch_loss=0.71416, batch_acc=0.406\n",
            "Step 16900, batch_loss=0.70458, batch_acc=0.438\n",
            "Step 17000, batch_loss=0.71192, batch_acc=0.438\n",
            "Validation accuracy: 0.492\n",
            "Step 17100, batch_loss=0.69518, batch_acc=0.500\n",
            "Step 17200, batch_loss=0.70140, batch_acc=0.500\n",
            "Step 17300, batch_loss=0.68664, batch_acc=0.562\n",
            "Step 17400, batch_loss=0.67671, batch_acc=0.594\n",
            "Step 17500, batch_loss=0.67965, batch_acc=0.656\n",
            "Step 17600, batch_loss=0.68277, batch_acc=0.594\n",
            "Step 17700, batch_loss=0.69184, batch_acc=0.531\n",
            "Step 17800, batch_loss=0.68191, batch_acc=0.625\n",
            "Step 17900, batch_loss=0.67492, batch_acc=0.625\n",
            "Step 18000, batch_loss=0.75047, batch_acc=0.406\n",
            "Validation accuracy: 0.507\n",
            "Step 18100, batch_loss=0.70974, batch_acc=0.438\n",
            "Step 18200, batch_loss=0.69128, batch_acc=0.531\n",
            "Step 18300, batch_loss=0.68723, batch_acc=0.562\n",
            "Step 18400, batch_loss=0.67551, batch_acc=0.594\n",
            "Step 18500, batch_loss=0.69317, batch_acc=0.500\n",
            "Step 18600, batch_loss=0.67135, batch_acc=0.656\n",
            "Step 18700, batch_loss=0.69272, batch_acc=0.531\n",
            "Step 18800, batch_loss=0.70856, batch_acc=0.312\n",
            "Step 18900, batch_loss=0.69432, batch_acc=0.500\n",
            "Step 19000, batch_loss=0.67767, batch_acc=0.625\n",
            "Validation accuracy: 0.492\n",
            "Step 19100, batch_loss=0.68625, batch_acc=0.562\n",
            "Step 19200, batch_loss=0.69130, batch_acc=0.531\n",
            "Step 19300, batch_loss=0.69138, batch_acc=0.562\n",
            "Step 19400, batch_loss=0.67721, batch_acc=0.594\n",
            "Step 19500, batch_loss=0.69457, batch_acc=0.469\n",
            "Step 19600, batch_loss=0.69303, batch_acc=0.719\n",
            "Step 19700, batch_loss=0.69927, batch_acc=0.438\n",
            "Step 19800, batch_loss=0.68545, batch_acc=0.562\n",
            "Step 19900, batch_loss=0.71100, batch_acc=0.406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7onI_ScUVssT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1c06521f-462a-43fe-e624-5f461e8612e6"
      },
      "source": [
        "# We can no longer fairly evaluate on the 2016 and 2018 validation sets since\n",
        "# they've been used for training. Instead, we only evaluate on the 2016 test set.\n",
        "\n",
        "predictions_2016 = predict_based_on_bert_binary_classifier(\n",
        "    test_2016_context_embs, test_2016_ending_0_embs, test_2016_ending_1_embs,\n",
        "    model_2)\n",
        "print('\\n2016 test accuracy: ' )\n",
        "print(compute_accuracy(test_2016_data, predictions_2016))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2016 test accuracy: \n",
            "0.51309460181721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4UrGlvgqrT3",
        "colab_type": "text"
      },
      "source": [
        "# Extra Credit\n",
        "For extra credit, make an account on [Codalab](https://competitions.codalab.org/) and submit your best model's outputs to the [Winter 2018 leaderboard](https://competitions.codalab.org/competitions/15333#participate-submit_results). You'll need to download the Winter 2018 CSV and create BERT embeddings for it.\n",
        "\n",
        "**If you choose to do the extra credit, please take a screenshot of the Codalab leaderboard  (including your submission) and paste it into your report. Your report should also include a description of the method that you used in your submission.**"
      ]
    }
  ]
}